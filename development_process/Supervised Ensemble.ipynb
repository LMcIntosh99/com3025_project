{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6dbd577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout, LSTM, Dense, Conv1D, MaxPooling1D, Flatten, LeakyReLU, Input, Concatenate\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16081f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([13097, 187, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SET = './PTB_train_set.pickle'\n",
    "TEST_SET = './PTB_test_set.pickle'\n",
    "\n",
    "with open(TEST_SET, 'rb') as file:\n",
    "    test_set = pickle.load(file)\n",
    "    x_test = test_set['x']\n",
    "    y_test = test_set['y']\n",
    "\n",
    "with open(TRAIN_SET, 'rb') as file:\n",
    "    train_set = pickle.load(file)\n",
    "    x_train = train_set['x']\n",
    "    y_train = train_set['y']\n",
    "    \n",
    "x_train = tf.expand_dims(x_train, axis=2)\n",
    "x_test = tf.expand_dims(x_test, axis=2)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea9f6352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 185, 5)            20        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 185, 5)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 92, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 89, 10)            210       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 89, 10)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 44, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 41, 20)            820       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 41, 20)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 20, 20)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 30)                12030     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 13,721\n",
      "Trainable params: 13,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN = Sequential()\n",
    "model_CNN.add(Conv1D(5, kernel_size=3, strides=1, input_shape=x_train.shape[1:]))\n",
    "model_CNN.add(LeakyReLU())\n",
    "model_CNN.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "model_CNN.add(Conv1D(10, kernel_size=4, strides=1))\n",
    "model_CNN.add(LeakyReLU())\n",
    "model_CNN.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "model_CNN.add(Conv1D(20, kernel_size=4, strides=1))\n",
    "model_CNN.add(LeakyReLU())\n",
    "model_CNN.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dense(30))\n",
    "model_CNN.add(LeakyReLU())\n",
    "model_CNN.add(Dense(20))\n",
    "model_CNN.add(LeakyReLU())\n",
    "model_CNN.add(Dense(1, activation=\"softmax\"))\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.003, momentum=0.7)\n",
    "model_CNN.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_CNN.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b34e8778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 64)                16896     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 25,345\n",
      "Trainable params: 25,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(LSTM(64, input_shape=(187,1)))\n",
    "model_LSTM.add(Dense(128, activation='relu'))\n",
    "model_LSTM.add(Dropout(0.3))\n",
    "model_LSTM.add(Dense(1, activation='softmax'))\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model_CNN.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a0be92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.51476103 0.48523897]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[0.5 0.5]], shape=(1, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.51476103, 0.48523897]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Demonstration of Ensemble Averaging\n",
    "def EnsembleAveraging(values):\n",
    "    factor = 1/len(values)\n",
    "    total = 0\n",
    "    for value in values:\n",
    "        total += values[0]*factor\n",
    "    return total\n",
    "\n",
    "a = model_CNN(tf.expand_dims(x_train[0], axis=0))\n",
    "b = model_LSTM(tf.expand_dims(x_train[0], axis=0))\n",
    "print(a)\n",
    "print(b)\n",
    "EnsembleAveraging([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05e78023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.62021255, 0.37978742]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Demonstration of Dense Layer Fusion\n",
    "a = model_CNN(tf.expand_dims(x_train[0], axis=0))\n",
    "b = model_LSTM(tf.expand_dims(x_train[0], axis=0))\n",
    "\n",
    "ab = Concatenate(axis=1)([a, b])\n",
    "\n",
    "Dense(2, activation=\"softmax\")(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a904dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EnsembleAveraging(values):\n",
    "    factor = 1/len(values)\n",
    "    total = 0\n",
    "    for value in values:\n",
    "        total += values[0]*factor\n",
    "    return total\n",
    "    \n",
    "\n",
    "def build_model():\n",
    "    inputs = Input(shape=(187, 1))\n",
    "    \n",
    "    x1 = model_LSTM(inputs)\n",
    "    x2 = model_CNN(inputs)\n",
    "\n",
    "\n",
    "    #outputs = EnsembleAveraging([x1, x2]) - was not able to train using this method\n",
    "    \n",
    "    x = Concatenate(axis=1)([x1, x2])\n",
    "    outputs = Dense(1, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Ensemble\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "ensemble = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "221a05da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 13s 130ms/step - loss: 0.5885 - accuracy: 0.7247 - val_loss: 0.6155 - val_accuracy: 0.6969\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = ensemble.fit(x_train, y_train, batch_size=128, epochs=1, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1c7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
